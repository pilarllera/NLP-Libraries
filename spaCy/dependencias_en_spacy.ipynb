{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2feMMmK67Uh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f5fec96-28b4-456b-9f15-3edce4ae3009"
      },
      "source": [
        "!pip install -U spacy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
            "  Downloading weasel-0.3.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
            "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "Installing collected packages: cloudpathlib, weasel, spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.6.1\n",
            "    Uninstalling spacy-3.6.1:\n",
            "      Successfully uninstalled spacy-3.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.6.0 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.7.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudpathlib-0.16.0 spacy-3.7.2 weasel-0.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bw8GIjb68r1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16083d3d-143d-4c75-cde9-2fd99842cd2f"
      },
      "source": [
        "# Descargamos uno de los modelos para español.\n",
        "!python -m spacy download es_core_news_lg"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-19 19:04:04.043831: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting es-core-news-lg==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_lg-3.6.0/es_core_news_lg-3.6.0-py3-none-any.whl (568.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.0/568.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-lg==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2.1.3)\n",
            "Installing collected packages: es-core-news-lg\n",
            "Successfully installed es-core-news-lg-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kygvC_jMDIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f6cb85d-77ec-489a-e62b-36ea6a8b2200"
      },
      "source": [
        "# Comprobamos la compatibilidad entre la versión de SpaCy de de los modelos descargados.\n",
        "!python -m spacy validate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-18 08:38:38.784092: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-18 08:38:39.816765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
            "\u001b[1m\n",
            "================= Installed pipeline packages (spaCy v3.7.2) =================\u001b[0m\n",
            "\u001b[38;5;4mℹ spaCy installation: /usr/local/lib/python3.10/dist-packages/spacy\u001b[0m\n",
            "\n",
            "NAME              SPACY            VERSION                            \n",
            "es_core_news_lg   >=3.7.0,<3.8.0   \u001b[38;5;2m3.7.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "en_core_web_sm    >=3.6.0,<3.7.0   \u001b[38;5;3m3.6.0\u001b[0m   --> 3.7.0     \n",
            "\n",
            "\u001b[1m\n",
            "============================== Install updates ==============================\u001b[0m\n",
            "Use the following commands to update the packages:\n",
            "python -m spacy download en_core_web_sm\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdBeDZFO68vM"
      },
      "source": [
        "# Importamos el módulo de SpaCy.\n",
        "import spacy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTzfEAPv68x7"
      },
      "source": [
        "# Cargamos uno de los modelos para español, entrenado a partir de un corpus mayoritariamente de noticias.\n",
        "es_nlp = spacy.load('es_core_news_lg')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUnyozdd7dhz"
      },
      "source": [
        "from nltk.tree import Tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zLR7Yey6UfO"
      },
      "source": [
        "# Creamos funciones que nos permiten mostrar los atributos morfológicos, las dependencias y el árbol de análisis de las oraciones.\n",
        "# Puedes utilizarlos para ver más claramente las oraciones con las que estés trabajando.\n",
        "\n",
        "def tok_format(tok):\n",
        "    return \"_\".join([tok.orth_, tok.tag_, tok.dep_])\n",
        "\n",
        "\n",
        "def to_nltk_tree(node):\n",
        "    if node.n_lefts + node.n_rights > 0:\n",
        "        return Tree(tok_format(node), [to_nltk_tree(child) for child in node.children])\n",
        "    else:\n",
        "        return tok_format(node)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Procesamos un texto con SpaCy y mostramos los atributos y el árbol dependencial de cada una de las oraciones.\n",
        "\n",
        "ejemplo = \"\"\"Mi perro persigue a su hijo en la bicicleta pero mi perro no sabe andar en bicicleta.\n",
        "Pruebo otro ejemplo de frase. A continuación, otra frase sin vuelta de carro.\"\"\"\n",
        "es_doc = es_nlp(ejemplo)\n",
        "\n",
        "for sent in es_doc.sents:\n",
        "  to_nltk_tree(sent.root).pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGnSjt2n4l-x",
        "outputId": "8c35e24f-e0ac-41b8-9aa4-e4eaea6c454e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                  persigue_VERB_RO                                                                             \n",
            "                                                                                         OT                                                                                    \n",
            "        _________________________________________________________________________________|______________________________________________________________________________        \n",
            "       |                          |                                     |                                        sabe_VERB_conj                                         |      \n",
            "       |                          |                                     |                                 _____________|________________________________                |       \n",
            "       |                          |                                     |                                |             |               |         andar_VERB_xcomp       |      \n",
            "       |                          |                                     |                                |             |               |                |               |       \n",
            "  Mi_DET_nsubj              hijo_NOUN_obj                        bicicleta_NOUN_o                        |             |        perro_NOUN_nsubj bicicleta_NOUN_o ._PUNCT_punct\n",
            "       |                          |                                     bl                               |             |               |                bl              |      \n",
            "       |              ____________|___________             _____________|________________                |             |               |                |               |       \n",
            "perro_PROPN_flat a_ADP_case               su_DET_det en_ADP_case                     la_DET_det    pero_CCONJ_cc no_ADV_advmod     mi_DET_det      en_ADP_case                 \n",
            "                                                                                                                                                                    _SPACE_dep \n",
            "\n",
            "              Pruebo_VERB_ROOT                                 \n",
            "       ______________|________________                          \n",
            "      |                        ejemplo_NOUN_obj                \n",
            "      |               ________________|________________         \n",
            "      |              |                          frase_NOUN_nmod\n",
            "      |              |                                 |        \n",
            "._PUNCT_punct   otro_DET_det                      de_ADP_case  \n",
            "\n",
            "                           frase_NOUN_ROOT                                                                          \n",
            "      ____________________________|________________________________________________________                          \n",
            "     |             |                             |                                  vuelta_NOUN_nmod                \n",
            "     |             |                             |                           ______________|________________         \n",
            "     |             |                        A_ADP_advmod                    |                        carro_NOUN_nmod\n",
            "     |             |               ______________|_____________             |                               |        \n",
            "otra_DET_det ._PUNCT_punct continuación_NOU              ,_PUNCT_punct sin_ADP_case                    de_ADP_case  \n",
            "                               N_fixed                                                                              \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHwYdXqI6mKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212654e5-26a7-4bc6-edb4-d1ad15428f57"
      },
      "source": [
        "# Observa el siguiente bloque de código, en el que se codifica sintácticamente la extracción del objeto de una pregunta.\n",
        "\n",
        "head_word = \"null\"\n",
        "question = \"¿En qué idiomas habla tu sobrino?\"\n",
        "\n",
        "es_doc = es_nlp(question)\n",
        "for sent in es_doc.sents:\n",
        "  for token in sent:\n",
        "    print(token, token.pos_, token.dep_, token.head)\n",
        "    if (token.dep_ == \"obj\" or token.dep_ == \"obl\") and (token.pos_ == \"NOUN\"):\n",
        "      head_word = token.text\n",
        "  print('\\n' + question + \"\\nSe pregunta por: \" + head_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿ PUNCT punct habla\n",
            "En ADP case idiomas\n",
            "qué DET det idiomas\n",
            "idiomas NOUN obl habla\n",
            "habla VERB ROOT habla\n",
            "tu DET det sobrino\n",
            "sobrino NOUN obj habla\n",
            "? PUNCT punct habla\n",
            "\n",
            "¿En qué idiomas habla tu sobrino?\n",
            "Se pregunta por: sobrino\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Observa ahora la aplicación de la estrategia anterior a un listado de oraciones:\n",
        "\n",
        "sentences = \"\"\"¿Qué plato quieres para cenar?\n",
        "¿Cuál es tu libro favorito?\n",
        "¿Qué música te gusta?\n",
        "¿A qué playa vas?\n",
        "¿De qué alumno es este examen?\"\"\".split('\\n')\n",
        "\n",
        "for sentence in sentences:\n",
        "  head_word = \"null\"\n",
        "  question = sentence\n",
        "\n",
        "  sent = es_nlp(question)\n",
        "  for token in sent:\n",
        "    print(token, token.pos_, token.dep_, token.head)\n",
        "    if (token.dep_ == \"obj\" or token.dep_ == \"obl\") and (token.pos_ == \"NOUN\"):\n",
        "      head_word = token.text\n",
        "  print('\\n' + question + \"\\nSe pregunta por: \" + head_word + '\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxIDqA9C8GCo",
        "outputId": "7af6d016-f330-4121-913d-b5c30d748184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿ PUNCT punct quieres\n",
            "Qué DET det plato\n",
            "plato NOUN obj quieres\n",
            "quieres VERB ROOT quieres\n",
            "para ADP mark cenar\n",
            "cenar VERB advcl quieres\n",
            "? PUNCT punct quieres\n",
            "\n",
            "¿Qué plato quieres para cenar?\n",
            "Se pregunta por: plato\n",
            "\n",
            "\n",
            "¿ PUNCT punct libro\n",
            "Cuál PRON nsubj libro\n",
            "es AUX cop libro\n",
            "tu DET det libro\n",
            "libro NOUN ROOT libro\n",
            "favorito ADJ amod libro\n",
            "? PUNCT punct libro\n",
            "\n",
            "¿Cuál es tu libro favorito?\n",
            "Se pregunta por: null\n",
            "\n",
            "\n",
            "¿ PUNCT punct gusta\n",
            "Qué DET det música\n",
            "música NOUN obj gusta\n",
            "te PRON obj gusta\n",
            "gusta VERB ROOT gusta\n",
            "? PUNCT punct gusta\n",
            "\n",
            "¿Qué música te gusta?\n",
            "Se pregunta por: música\n",
            "\n",
            "\n",
            "¿ PUNCT punct vas\n",
            "A ADP case playa\n",
            "qué DET det playa\n",
            "playa NOUN obj vas\n",
            "vas VERB ROOT vas\n",
            "? PUNCT punct vas\n",
            "\n",
            "¿A qué playa vas?\n",
            "Se pregunta por: playa\n",
            "\n",
            "\n",
            "¿ PUNCT punct examen\n",
            "De ADP case alumno\n",
            "qué DET det alumno\n",
            "alumno NOUN nsubj examen\n",
            "es AUX cop examen\n",
            "este DET det examen\n",
            "examen NOUN ROOT examen\n",
            "? PUNCT punct examen\n",
            "\n",
            "¿De qué alumno es este examen?\n",
            "Se pregunta por: null\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pregunta 1: Centra tu análisis en aquellas oraciones para las que el bloque de código anterior no extrae el objeto de la pregunta.\n",
        "# Categoriza los errores en categorías y refina la estrategia de extracción para que funciones también con esas oraciones.\n",
        "# Comprueba, además, que continúan analizándose correctamente las oraciones del listado original.\n",
        "\n",
        "# he hecho el códido de dos maneras distintas:\n",
        "# la primera tiene un elif por cada error que quiero solucionar:\n",
        "\n",
        "import spacy\n",
        "\n",
        "sentences = \"\"\"¿Qué plato quieres para cenar?\n",
        "¿Cuál es tu libro favorito?\n",
        "¿Qué música te gusta?\n",
        "¿A qué playa vas?\n",
        "¿De qué alumno es este examen?\"\"\".split('\\n')\n",
        "\n",
        "for sentence in sentences:\n",
        "  head_word = \"null\"\n",
        "  question = sentence\n",
        "\n",
        "  sent = es_nlp(question)\n",
        "  for token in sent:\n",
        "    print(token, token.pos_, token.dep_, token.head)\n",
        "    if (token.dep_ == \"obj\" or token.dep_ == \"obl\") and (token.pos_ == \"NOUN\"):\n",
        "      head_word = token.text\n",
        "      break\n",
        "    if (token.dep_ == \"nsubj\") and (token.pos_ == \"NOUN\"):\n",
        "      head_word = token.text\n",
        "      break\n",
        "    if (token.dep_ == \"ROOT\") and (token.pos_ == \"NOUN\"):\n",
        "      head_word = token.text\n",
        "      break\n",
        "  print('\\n' + question + \"\\nSe pregunta por: \" + head_word + '\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCg3-t-qAHLo",
        "outputId": "bd30e9ca-977b-4a33-f918-b42b29e634f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿ PUNCT punct quieres\n",
            "Qué DET det plato\n",
            "plato NOUN obj quieres\n",
            "\n",
            "¿Qué plato quieres para cenar?\n",
            "Se pregunta por: plato\n",
            "\n",
            "\n",
            "¿ PUNCT punct libro\n",
            "Cuál PRON nsubj libro\n",
            "es AUX cop libro\n",
            "tu DET det libro\n",
            "libro NOUN ROOT libro\n",
            "\n",
            "¿Cuál es tu libro favorito?\n",
            "Se pregunta por: libro\n",
            "\n",
            "\n",
            "¿ PUNCT punct gusta\n",
            "Qué DET det música\n",
            "música NOUN obj gusta\n",
            "\n",
            "¿Qué música te gusta?\n",
            "Se pregunta por: música\n",
            "\n",
            "\n",
            "¿ PUNCT punct vas\n",
            "A ADP case playa\n",
            "qué DET det playa\n",
            "playa NOUN obj vas\n",
            "\n",
            "¿A qué playa vas?\n",
            "Se pregunta por: playa\n",
            "\n",
            "\n",
            "¿ PUNCT punct examen\n",
            "De ADP case alumno\n",
            "qué DET det alumno\n",
            "alumno NOUN nsubj examen\n",
            "\n",
            "¿De qué alumno es este examen?\n",
            "Se pregunta por: alumno\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pregunta 2: Comprueba, con algunos ejemplo más, que tu estrategia analiza correctamente otras oraciones de las mismas categorías que has descrito.\n",
        "\n",
        "sentences = \"\"\"¿Te gustan los gatos?\n",
        "¿Cuál es tu deporte favorito?\n",
        "¿Qué carrera has estudiado?\n",
        "¿A qué ciudad vas?\n",
        "¿De qué niño es este juguete?\n",
        "¿Cuánto cuesta aquí el pantalón?\"\"\".split('\\n')\n",
        "\n",
        "for sentence in sentences:\n",
        "  head_word = \"null\"\n",
        "  question = sentence\n",
        "\n",
        "  sent = es_nlp(question)\n",
        "  for token in sent:\n",
        "    print(token, token.pos_, token.dep_, token.head)\n",
        "    if (token.dep_ == \"obj\" or token.dep_ == \"obl\") and (token.pos_ == \"NOUN\"):\n",
        "      head_word = token.text\n",
        "      break\n",
        "    if (token.dep_ == \"nsubj\") and (token.pos_ == \"NOUN\"):\n",
        "      head_word = token.text\n",
        "      break\n",
        "    if (token.dep_ == \"ROOT\") and (token.pos_ == \"NOUN\"):\n",
        "      head_word = token.text\n",
        "      break\n",
        "  print('\\n' + question + \"\\nSe pregunta por: \" + head_word + '\\n\\n')"
      ],
      "metadata": {
        "id": "OeLmv9IwCrJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58a8ec6b-2cef-46bb-f7e6-ed5ee1069b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿ PUNCT punct gustan\n",
            "Te PRON obj gustan\n",
            "gustan VERB ROOT gustan\n",
            "los DET det gatos\n",
            "gatos NOUN nsubj gustan\n",
            "\n",
            "¿Te gustan los gatos?\n",
            "Se pregunta por: gatos\n",
            "\n",
            "\n",
            "¿ PUNCT punct deporte\n",
            "Cuál PRON nsubj deporte\n",
            "es AUX cop deporte\n",
            "tu DET det deporte\n",
            "deporte NOUN ROOT deporte\n",
            "\n",
            "¿Cuál es tu deporte favorito?\n",
            "Se pregunta por: deporte\n",
            "\n",
            "\n",
            "¿ PUNCT punct estudiado\n",
            "Qué DET det carrera\n",
            "carrera NOUN obj estudiado\n",
            "\n",
            "¿Qué carrera has estudiado?\n",
            "Se pregunta por: carrera\n",
            "\n",
            "\n",
            "¿ PUNCT punct vas\n",
            "A ADP case ciudad\n",
            "qué DET det ciudad\n",
            "ciudad NOUN obl vas\n",
            "\n",
            "¿A qué ciudad vas?\n",
            "Se pregunta por: ciudad\n",
            "\n",
            "\n",
            "¿ PUNCT punct juguete\n",
            "De ADP case qué\n",
            "qué PRON det niño\n",
            "niño NOUN nsubj juguete\n",
            "\n",
            "¿De qué niño es este juguete?\n",
            "Se pregunta por: niño\n",
            "\n",
            "\n",
            "¿ PUNCT punct cuesta\n",
            "Cuánto PRON obj cuesta\n",
            "cuesta VERB ROOT cuesta\n",
            "aquí ADV advmod cuesta\n",
            "el DET det pantalón\n",
            "pantalón NOUN nsubj cuesta\n",
            "\n",
            "¿Cuánto cuesta aquí el pantalón\n",
            "Se pregunta por: pantalón\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pregunta 3: Comprueba si tu estrategia falla en alguna categoría de oraciones más y reflexiona sobre qué estrategia podría seguirse para contemplar dicha casuística.\n",
        "# Es posible que la salida de este modelo de SpaCy no permite solucionar el problema. Si es así, comenta igualmente qué información lingüística sería necesario codificar para solucionar el problema.\n",
        "sentences = \"\"\"¿Quién de tus amigos fue el que te invitó?\n",
        "¿Cuáles son tus deportes favoritos?\n",
        "¿Quién vino?\n",
        "¿Cuántas veces has visto la película \"\"\".split('\\n')\n",
        "\n",
        "for sentence in sentences:\n",
        "  head_word = \"null\"\n",
        "  question = sentence\n",
        "\n",
        "  sent = es_nlp(question)\n",
        "  for token in sent:\n",
        "    print(token, token.pos_, token.dep_, token.head)\n",
        "    if (token.dep_ == \"obj\" or token.dep_ == \"obl\") and (token.pos_ == \"NOUN\"):\n",
        "      head_word = token.text\n",
        "      break\n",
        "    if (token.dep_ == \"nsubj\") and (token.pos_ == \"NOUN\"):\n",
        "      head_word = token.text\n",
        "      break\n",
        "    if (token.dep_ == \"ROOT\") and (token.pos_ == \"NOUN\"):\n",
        "      head_word = token.text\n",
        "      break\n",
        "  print('\\n' + question + \"\\nSe pregunta por: \" + head_word + '\\n\\n')"
      ],
      "metadata": {
        "id": "Q977k-ltDAAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e624de6-3dc5-4661-fd4c-e110520fa188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿ PUNCT punct fue\n",
            "Quién PRON nsubj fue\n",
            "de ADP case amigos\n",
            "tus DET det amigos\n",
            "amigos NOUN nmod Quién\n",
            "fue AUX ROOT fue\n",
            "el DET det invitó\n",
            "que PRON obj invitó\n",
            "te PRON iobj invitó\n",
            "invitó VERB ccomp fue\n",
            "? PUNCT punct fue\n",
            "\n",
            "¿Quién de tus amigos fue el que te invitó?\n",
            "Se pregunta por: null\n",
            "\n",
            "\n",
            "¿ PUNCT punct deportes\n",
            "Cuáles PRON nsubj deportes\n",
            "son AUX cop deportes\n",
            "tus DET det deportes\n",
            "deportes NOUN ROOT deportes\n",
            "\n",
            "¿Cuáles son tus deportes favoritos?\n",
            "Se pregunta por: deportes\n",
            "\n",
            "\n",
            "¿ PUNCT punct vino\n",
            "Quién PRON nsubj vino\n",
            "vino VERB ROOT vino\n",
            "? PUNCT punct vino\n",
            "\n",
            "¿Quién vino?\n",
            "Se pregunta por: null\n",
            "\n",
            "\n",
            "¿ PUNCT punct visto\n",
            "Cuántas DET det veces\n",
            "veces NOUN obl visto\n",
            "\n",
            "¿Cuántas veces has visto la película \n",
            "Se pregunta por: veces\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Me da error en la primera y en la cuarta frase\n",
        "# La manera de solucionarlo es añadir como posibilidad los pronombres de sujeto y obl.\n",
        "# Sin embargo necesitaríamos una gramática que infiriera que cuando se pregunta \"¿Cómo te llamas?\" no\n",
        "# se pregunta por cómo, sino por su nombre.\n",
        "sentences = \"\"\"¿Quién de tus amigos fue el que te invitó?\n",
        "¿Cuáles son tus deportes favoritos?\n",
        "¿Cómo te llamas?\n",
        "¿Cuántas veces has visto la película \"\"\".split('\\n')\n",
        "\n",
        "for sentence in sentences:\n",
        "  head_word = \"null\"\n",
        "  question = sentence\n",
        "\n",
        "  sent = es_nlp(question)\n",
        "  for token in sent:\n",
        "    print(token, token.pos_, token.dep_, token.head)\n",
        "    if (token.dep_ == \"obj\" or token.dep_ == \"obl\") and (token.pos_ == \"NOUN\" or token.pos_ == \"PRON\"):\n",
        "      head_word = token.text\n",
        "      break\n",
        "    if (token.dep_ == \"nsubj\") and (token.pos_ == \"NOUN\" or token.pos_ == \"PRON\"):\n",
        "      head_word = token.text\n",
        "      break\n",
        "    if (token.dep_ == \"ROOT\") and (token.pos_ == \"NOUN\"):\n",
        "      head_word = token.text\n",
        "      break\n",
        "  print('\\n' + question + \"\\nSe pregunta por: \" + head_word + '\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ1GD33ow7jG",
        "outputId": "c516bf7a-0fec-4a4f-cdee-1d5d42787f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿ PUNCT punct fue\n",
            "Quién PRON nsubj fue\n",
            "\n",
            "¿Quién de tus amigos fue el que te invitó?\n",
            "Se pregunta por: Quién\n",
            "\n",
            "\n",
            "¿ PUNCT punct deportes\n",
            "Cuáles PRON nsubj deportes\n",
            "\n",
            "¿Cuáles son tus deportes favoritos?\n",
            "Se pregunta por: Cuáles\n",
            "\n",
            "\n",
            "¿ PUNCT punct llamas\n",
            "Cómo PRON obl llamas\n",
            "\n",
            "¿Cómo te llamas?\n",
            "Se pregunta por: Cómo\n",
            "\n",
            "\n",
            "¿ PUNCT punct visto\n",
            "Cuántas DET det veces\n",
            "veces NOUN obl visto\n",
            "\n",
            "¿Cuántas veces has visto la película \n",
            "Se pregunta por: veces\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AAARy5RMgrC",
        "outputId": "46793566-b875-476b-e7a1-8516456e83d2"
      },
      "source": [
        "# Observa el siguiente bloque de código, con el que se pretende extraer tripletas (tuplas de 3 elementos) sujeto-verbo-objeto\n",
        "\n",
        "oraciones = \"Juan compra caramelos. Juan se queja sobre los exámenes\"\n",
        "es_doc = es_nlp(oraciones)\n",
        "for sent in es_doc.sents:\n",
        "  t_1 = \"null\"\n",
        "  t_2 = \"null\"\n",
        "  t_3 = \"null\"\n",
        "  for token in sent:\n",
        "      print(token, token.pos_, token.dep_, token.head)\n",
        "      if token.dep_ == \"nsubj\":\n",
        "          t_1 = token.text\n",
        "      if token.dep_ == \"ROOT\":\n",
        "          t_2 = token.text\n",
        "      if token.dep_ == \"obj\":\n",
        "          t_3 = token.text\n",
        "  print('\\n' + sent.orth_ + \"\\n(\" + t_1 + ', ' + t_2 + ', ' + t_3 + \")\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Juan PROPN nsubj compra\n",
            "compra VERB ROOT compra\n",
            "caramelos NOUN obj compra\n",
            ". PUNCT punct compra\n",
            "\n",
            "Juan compra caramelos.\n",
            "(Juan, compra, caramelos)\n",
            "\n",
            "Juan PROPN nsubj queja\n",
            "se PRON expl:pv queja\n",
            "queja VERB ROOT queja\n",
            "sobre ADP case exámenes\n",
            "los DET det exámenes\n",
            "exámenes NOUN obl queja\n",
            "\n",
            "Juan se queja sobre los exámenes\n",
            "(Juan, queja, null)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pregunta 4: Refina el bloque de código anterior para que extraiga objetos con preposición.\n",
        "# Añade más oraciones para comprobar la cobertura de tu estrategia. En el caso de encontrar errores, categorízalos y reflexiona sobre qué estrategia podría seguirse para contemplar dicha casuística.\n",
        "oraciones = \"Juan compra caramelos. Juan se queja sobre los exámenes.Juan trabaja con su padre.Juan habla de la vida.Juan se duerme encima del sofá.Juan sale con sus amigos. A Juan le encanta pasear por la playa\"\n",
        "\n",
        "es_doc = es_nlp(oraciones)\n",
        "for sent in es_doc.sents:\n",
        "  t_1 = \"null\"\n",
        "  t_2 = \"null\"\n",
        "  t_3 = \"null\"\n",
        "  for token in sent:\n",
        "      print(token, token.pos_, token.dep_, token.head)\n",
        "      if(token.dep_ == \"nsubj\") or (token.pos_ == \"PROPN\"):\n",
        "          t_1 = token.text\n",
        "      if token.dep_ == \"ROOT\":\n",
        "          t_2 = token.text\n",
        "      if (token.dep_ == \"obl\" or token.dep_ == \"obj\" ) and (token.pos_ == \"NOUN\"):\n",
        "          t_3 = token.text\n",
        "  print('\\n' + sent.orth_ + \"\\n(\" + t_1 + ', ' + t_2 + ', ' + t_3 + \")\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqrOgQ_OExDV",
        "outputId": "949fe86c-f7d7-4627-cb78-753ad7a3978e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Juan PROPN nsubj compra\n",
            "compra VERB ROOT compra\n",
            "caramelos NOUN obj compra\n",
            ". PUNCT punct compra\n",
            "\n",
            "Juan compra caramelos.\n",
            "(Juan, compra, caramelos)\n",
            "\n",
            "Juan PROPN nsubj queja\n",
            "se PRON expl:pv queja\n",
            "queja VERB ROOT queja\n",
            "sobre ADP case exámenes\n",
            "los DET det exámenes\n",
            "exámenes NOUN obl queja\n",
            ". PUNCT punct queja\n",
            "\n",
            "Juan se queja sobre los exámenes.\n",
            "(Juan, queja, exámenes)\n",
            "\n",
            "Juan PROPN nsubj trabaja\n",
            "trabaja VERB ROOT trabaja\n",
            "con ADP case padre\n",
            "su DET det padre\n",
            "padre NOUN obl trabaja\n",
            ". PUNCT punct trabaja\n",
            "\n",
            "Juan trabaja con su padre.\n",
            "(Juan, trabaja, padre)\n",
            "\n",
            "Juan PROPN nsubj habla\n",
            "habla VERB ROOT habla\n",
            "de ADP case vida\n",
            "la DET det vida\n",
            "vida NOUN obj habla\n",
            ". PUNCT punct habla\n",
            "\n",
            "Juan habla de la vida.\n",
            "(Juan, habla, vida)\n",
            "\n",
            "Juan PROPN nsubj duerme\n",
            "se PRON expl:pv duerme\n",
            "duerme VERB ROOT duerme\n",
            "encima ADV advmod duerme\n",
            "del ADP case sofá\n",
            "sofá NOUN obl duerme\n",
            ". PUNCT punct duerme\n",
            "\n",
            "Juan se duerme encima del sofá.\n",
            "(Juan, duerme, sofá)\n",
            "\n",
            "Juan PROPN nsubj sale\n",
            "sale VERB ROOT sale\n",
            "con ADP case amigos\n",
            "sus DET det amigos\n",
            "amigos NOUN obl sale\n",
            ". PUNCT punct sale\n",
            "\n",
            "Juan sale con sus amigos.\n",
            "(Juan, sale, amigos)\n",
            "\n",
            "A ADP case Juan\n",
            "Juan PROPN obj encanta\n",
            "le PRON obj encanta\n",
            "encanta VERB ROOT encanta\n",
            "pasear VERB csubj encanta\n",
            "por ADP case playa\n",
            "la DET det playa\n",
            "playa NOUN obl pasear\n",
            "\n",
            "A Juan le encanta pasear por la playa\n",
            "(Juan, encanta, playa)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0FtDMWiMvFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64c540b2-3a34-4cf6-b9be-580b2385d3f0"
      },
      "source": [
        "# Pregunta 5: Diseña una estrategia para extraer listas de tuplas nombre-complemento(adyacente) de un texto, tal y como se muestra a continuación:\n",
        "# Pista: una posible solución del problema pasa por utilizar un id de cada sustantivo del texto.\n",
        "# Para ello, podemos utilizar la posición del token en el texto, accesible a partir del atributo i del objeto Token.\n",
        "\n",
        "texto = \"\"\"El peor día de mi vida fue cuando descubrí los enormes problemas de sobrevivir en una ciudad extranjera sin red de apoyo.\n",
        "Cuando crees que la cosa no puede ser peor, te das cuenta de que la vida siempre puede sorprenderte con un nuevo imprevisto.\n",
        "\"\"\"\n",
        "es_doc = es_nlp(texto)\n",
        "tuplas = []\n",
        "for sent in es_doc.sents:\n",
        "  to_nltk_tree(sent.root).pretty_print()\n",
        "\n",
        "for sent in es_doc.sents:\n",
        "    for token in sent:\n",
        "        if (token.pos_ == \"NOUN\"):\n",
        "            for child in token.children:\n",
        "                if (child.pos_ == \"ADJ\") or (child.dep_ == \"nmod\") or (child.pos_ == \"VERB\"):\n",
        "                    tuplas.append((token.text, child.text))\n",
        "\n",
        "print(tuplas)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                              fue_AUX_ROOT                                                                                                                          \n",
            "                  _________________________________________________________________________________|_________________________________________________________________________________________________________________________        \n",
            "                 |                                                                          descubrí_VERB_cc                                                                                                                 |      \n",
            "                 |                                                                                omp                                                                                                                        |      \n",
            "                 |                                                     ____________________________|____________________________                                                                                             |       \n",
            "                 |                                                    |                                                  problemas_NOUN_o                                                                                    |      \n",
            "                 |                                                    |                                                         bj                                                                                           |      \n",
            "                 |                                                    |               __________________________________________|________________                                                                            |       \n",
            "                 |                                                    |              |             |                                      sobrevivir_VERB_                                                                   |      \n",
            "                 |                                                    |              |             |                                            acl                                                                          |      \n",
            "                 |                                                    |              |             |               ______________________________|________________                                                           |       \n",
            "                 |                                                    |              |             |              |                                        ciudad_NOUN_obl                                                   |      \n",
            "                 |                                                    |              |             |              |              _________________________________|____________________________                              |       \n",
            "            día_NOUN_obl                                              |              |             |              |             |                |                |                      red_NOUN_nmod                       |      \n",
            "     ____________|_________________________                           |              |             |              |             |                |                |               _____________|______________               |       \n",
            "    |            |                   vida_NOUN_nmod                   |              |             |              |             |                |                |              |                     apoyo_NOUN_nmod ._PUNCT_punct\n",
            "    |            |             ____________|____________              |              |             |              |             |                |                |              |                            |              |       \n",
            "El_DET_det peor_ADJ_amod de_ADP_case                mi_DET_det cuando_SCONJ_mar los_DET_det enormes_ADJ_amod de_ADP_mark   en_ADP_case      una_DET_det    extranjera_ADJ_a sin_ADP_case                 de_ADP_case                \n",
            "                                                                      k                                                                                          mod                                                     _SPACE_dep \n",
            "\n",
            "                                                                                                                               crees_VERB_ROOT                                                                                                                                           \n",
            "        ______________________________________________________________________________________________________________________________|_______________                                                                                                                                    \n",
            "       |               |           |                                                                                                            peor_ADJ_ccomp                                                                                                                           \n",
            "       |               |           |             _____________________________________________________________________________________________________|___________________________________________                                                                                        \n",
            "       |               |           |            |              |             |            |            |              |                                                                     das_VERB_advcl                                                                               \n",
            "       |               |           |            |              |             |            |            |              |                ___________________________________________________________|________________                                                                       \n",
            "       |               |           |            |              |             |            |            |              |               |               |                                                     sorprenderte_VER                                                             \n",
            "       |               |           |            |              |             |            |            |              |               |               |                                                         B_xcomp                                                                  \n",
            "       |               |           |            |              |             |            |            |              |               |               |               _____________________________________________|_____________________________________________                         \n",
            "       |               |           |            |              |             |            |            |       cosa_NOUN_nsubj        |               |              |            |               |                |         vida_NOUN_nsubj              imprevisto_NOUN_               \n",
            "       |               |           |            |              |             |            |            |              |               |               |              |            |               |                |                |                           obl                      \n",
            "       |               |           |            |              |             |            |            |              |               |               |              |            |               |                |                |              ______________|_______________         \n",
            "Cuando_SCONJ_mar ._PUNCT_punct            que_SCONJ_mark no_ADV_advmod puede_AUX_aux ser_AUX_cop ,_PUNCT_punct    la_DET_det   te_PRON_expl:pv cuenta_NOUN_comp de_ADP_mark que_SCONJ_mark siempre_ADV_advm  puede_AUX_aux      la_DET_det   con_ADP_case    un_DET_det    nuevo_ADJ_amod\n",
            "       k                       _SPACE_dep                                                                                                            ound                                         od                                                                                     \n",
            "\n",
            "[('día', 'peor'), ('día', 'vida'), ('problemas', 'enormes'), ('problemas', 'sobrevivir'), ('ciudad', 'extranjera'), ('ciudad', 'red'), ('red', 'apoyo'), ('imprevisto', 'nuevo')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Observa la salida esperada del ejercicio y fíjate en la inclusión errónea de la tupla (ciudad, red).\n",
        "# ¿A qué obedece ese fallo? ¿Debemos refinar nuestra estrategia para solventarlo?\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t9PY2WwJi30",
        "outputId": "bad32075-1162-4ecf-e316-c5f128c1df85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(día, peor), (día, vida), (problemas, enormes), (problemas, sobrevivir), (ciudad, extranjera), (ciudad, red), (red, apoyo), (imprevisto, nuevo)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# se debe a que \"red\" cumple los criterios de sustantivo y nmod, si le decimos que no tenga en cuenta las palabras\n",
        "# que cumplen esos criterios, entonces eliminaría también (día, vida). El problema es que el árbol lo identifica\n",
        "#como un modificador de \"ciudad\" cuando realmente no lo es.\n"
      ],
      "metadata": {
        "id": "LSYjzXLnKmnW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}